# Software-Defect-Prediction-Research
## Objective
Create a cross-project software defect prediction model using Neural Network algorithm, which would require less prior data to train the model[1].
## background
Predicting defects within the software is the process of identifying any file or module that potentially contains a bug, which is referring to a logical error or flaw within the software. To be able to predict defects within the software we need to identify some set of features that can be used to measure the quality of the code. These features can be handcrafted or extracted from the source code of the program. These features are commonly referred to as a metric, and there are several metrics that can be used to measure the quality of the code. One example is Halstead’s metric, which measures the complexity of software based on the number of unique operators and operands the software contains [4]. Another common use metric is the McCabe metrics, which measure software complexity based on four types of metrics. Cyclomatic complexity, which measures how complicated a program flowgraph is. Essential complexity discusses how much can a flowgraph be simplified. Design complexity is the combination of the two previous complexities, because it measures the complexity of the reduced flowgraph of the program[5]. By utilizing such metrics computer scientists can build a classification model that determines whether a section of code contains a defect. One common type of classification model used for this purpose is a neural network. A neural network is a connection of node connected by edges in a feedforward mannered that replicate the function of neuron found in the human brain, the structure contains an input layer, a hidden, layer, and an output later. Typically this type of model is chosen due to its non-linear learning that occurs in the hidden layer of the network [6]. 
For the purposes of classifying defects within the software, there are several variations of neural networks which are utilized. One of which is a convolutional network, which is a neural network algorithm that is ideal when working with visual input [7]. As opposed to the traditionally handcrafted metric such as Halstead’s metric, features can be extracted from the source file, Jian Li argues that traditional handcrafted features are not representative of software, because they fail to capture the well-defined syntax and rich semantics that is contained in the Abstract Syntax Tree of the program. Using a convolutional neural network, Jian Li was able to create a software prediction model using several datasets such as camel, jEdit, Lucene, Xalan, Xerces, synapse, and poi. With this model to get the best accuracy it is necessary to adjust some of the filter sizes and the number of filters to find the best configuration for the project. The authors discover that in terms of the f-score of The convolutional network, the model performs “16% better than compare to a traditional featured-based method”[8]. 
Both handcrafted features or feature extraction relied on the code or module to identify any potential defect in the software. These metrics are commonly referred to as code metrics. Another type of metric commonly used is process metrics. Unlike a code metric a process metric measures different attributes which relate to the development of the project as opposed to the code. Some examples of the properties which are measured are developer count, code ownership, developer experience, and change frequency. The idea behind such a metric is that the developer and the development process play as much, if not a greater role when it comes to creating a defect in a code as the code itself[9]. F-score is an evaluation metric that measures the overall performance of a model by combining both precision and recall.
 Most models that are created for the defect prediction are trained on the same project that they will be tested which is called within-project defect. Another type of model is called cross-project defect prediction which is when the training and testing are done on separate projects. Ideally, cross-project defect prediction would provide better insight but it comes with several limitations. Cross-project defect prediction boasts some of the lowest accuracies due to the difference between the project use for training and testing[8]. Currently, this problem is being addressed by Nam et all who believe the solution is a transfer learning technique called Transfer Component Analysis[10]. The objective of this research project is to create a cross-project software prediction model using a Neural Network, that will help developers allocate their effort to files or modules that most likely contain defects and therefore increase productivity and reduce testing time.[8]

References
[1]	I. Binanto, H. L. H. Spits Warnars, F. Gaol, E. Abdurachman, and B. Soewito, “Measuring the quality of various version an object-oriented software utilizing CK metrics,” Mar. 2018, pp. 41–44. doi: 10.1109/ICOIACT.2018.8350760.
[2]	G. Fan, X. Diao, H. Yu, K. Yang, and L. Chen, “Software Defect Prediction via Attention-Based Recurrent Neural Network,” Scientific Programming, vol. 2019, p. e6230953, Apr. 2019, doi: 10.1155/2019/6230953.
[3]	A. Shaik, C. Reddy, and A. Damodaram, “Object Oriented Software Metrics and Quality Assessment: Current State of the Art,” Feb. 2023.
[4]	“Software Engineering | Halstead’s Software Metrics,” GeeksforGeeks, Nov. 07, 2017. https://www.geeksforgeeks.org/software-engineering-halsteads-software-metrics/ (accessed Apr. 20, 2023).
[5]	“PROMISE Software Engineering Repository.” http://promise.site.uottawa.ca/SERepository/ (accessed Mar. 05, 2023).
[6]	Chantal D. Larose and Daniel T. Larose, “NEURAL NETWORKS,” in Data Science Using Python and R, Wiley.
[7]	Sumit Saha, “Towards Data Science,” A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way, Dec. 15, 2018. https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53 (accessed Feb. 20, 2023).
[8]	J. Li, P. He, J. Zhu, and M. R. Lyu, “Software Defect Prediction via Convolutional Neural Network,” in 2017 IEEE International Conference on Software Quality, Reliability and Security (QRS), Jul. 2017, pp. 318–328. doi: 10.1109/QRS.2017.42.
[9]	F. Rahman and P. Devanbu, “How, and why, process metrics are better,” in 2013 35th International Conference on Software Engineering (ICSE), May 2013, pp. 432–441. doi: 10.1109/ICSE.2013.6606589.
[10]	J. Nam, S. J. Pan, and S. Kim, “Transfer defect learning,” in 2013 35th International Conference on Software Engineering (ICSE), May 2013, pp. 382–391. doi: 10.1109/ICSE.2013.6606584.
[11]	“SMOTE and ADASYN ( Handling Imbalanced Data Set ) | by Indresh Bhattacharyya | Medium.” https://medium.com/coinmonks/smote-and-adasyn-handling-imbalanced-data-set-34f5223e167 (accessed Apr. 21, 2023).
[12]	“Choosing a Baseline Accuracy for a Classification Model | by Aaron Lee | Towards Data Science.” https://towardsdatascience.com/calculating-a-baseline-accuracy-for-a-classification-model-a4b342ceb88f (accessed May 08, 2023).

